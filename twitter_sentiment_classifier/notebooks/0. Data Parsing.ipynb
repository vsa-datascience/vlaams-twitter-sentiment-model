{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 331 µs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rubenbroekx/Documents/Projects/twitter-sentiment-classifier/twitter_sentiment_classifier\n",
      "time: 1.29 ms\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "\n",
    "This script reads in the raw annotated dataset and translates this to a better formatted format. Information that isn't necessary or is prone to change later in the pipeline (e.g. sentence encodings) are removed as well.\n",
    "\n",
    "The input of this script is the raw `annotations.jsonl` file that is used in the Prodigy annotation tool. This file will be cleaned and transformed (since it contains several deprecated fields) with as result the `tweets_annotated.jsonl` file.\n",
    "\n",
    "**Note: Since the raw data isn't provided, it will not be able to run this script on your local machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.53 ms\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> JSONDecoderError\n",
      "Loaded in 49576 annotations\n",
      "time: 9.88 s\n"
     ]
    }
   ],
   "source": [
    "# Read in the data, be aware of possible parsing error (due to OOM on EC2)\n",
    "with open(os.path.expanduser('~/data/twitter/annotations.jsonl'), 'r') as f:\n",
    "    annotations = []\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        try:\n",
    "            annotations.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(' -> JSONDecoderError')\n",
    "            pass\n",
    "        finally:\n",
    "            line = f.readline()\n",
    "print(f\"Loaded in {len(annotations)} annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 51576 annotations\n",
      "time: 443 ms\n"
     ]
    }
   ],
   "source": [
    "# Extend with extra annotations performed locally\n",
    "with open(os.path.expanduser('~/data/twitter/extra/annotations_extra.jsonl'), 'r') as f:\n",
    "    annotations += [json.loads(line) for line in f.readlines()]\n",
    "print(f\"Loaded in {len(annotations)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields\n",
    "\n",
    "The raw data has plenty of fields:\n",
    "- **id** The unique tweet ID of the sample\n",
    "- **created_at** The creation date of the tweet\n",
    "- **text** The cleaned text of the tweet\n",
    "- **text_raw** The raw text of the tweet \n",
    "- **truncated** Flag if the tweet is truncated or not\n",
    "- **is_quote** Flag if the tweet was a quote or not\n",
    "- **quoted_lang** The language of the tweet\n",
    "- **quoted_tweet** The processed text of the quoted tweet, if it exists\n",
    "- **quoted_tweet_raw** The raw text of the quoted tweet, if it exists\n",
    "- **quote_count** Number of times the tweet (of **id**) is quoted\n",
    "- **is_reply** Flag if the tweet is a reply itself\n",
    "- **replied_tweet_id** The ID of the tweet to which this tweet applies to\n",
    "- **reply_count** Number of replies on the tweet\n",
    "- **retweet_count** Number of times the tweet is retweeted\n",
    "- **favorite_count** Number of times the tweet is favored\n",
    "- **hashtags** The hashtags present in the tweet\n",
    "- **user_followers** The number of followers the tweet's creator has\n",
    "- **user_friends** The number of friends the tweet's creator has\n",
    "- **user_verified** Flag if the creator is a verified Twitter user\n",
    "- **user_tweet_count** Number of tweets sent by the creator during the account's lifetime\n",
    "- **user_created_at** Account creation date\n",
    "- **features** Sentence embedding\n",
    "- **prediction** Prediction of the model that was used during training\n",
    "- **_input_hash** Input-hash ID of the tweet, as defined by Prodigy\n",
    "- **_task_hash** Task-hash ID of the tweet, as defined by Prodigy\n",
    "- **meta** Meta-data attached to the tweet\n",
    "- **_session_id** Session-ID, indicating which annotator was annotating\n",
    "- **answer** Indication if the tweet is accepted or not\n",
    "- **annotators** All annotators of the tweet\n",
    "- **sentiment** Annotated sentiment\n",
    "- **__label** Annotated sentiment label\n",
    "- **flagged** Flag indicating that the annotator flagged the tweet\n",
    "- **validation** Flag indicating that the tweet has been flagged before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update data\n",
    "\n",
    "Update the data over a set of rules:\n",
    "1. Anonymise annotators; substitute `_session_id` names with anonymised representations (such as unique letters)\n",
    "2. Update the `annotators` field with the new annotators names and correct missing annotators (since added incrementally)\n",
    "3. Make the assigned labels easy readable \n",
    "4. Assign `flag` label to tweets which were flagged by at least one user\n",
    "5. Flag disagreement in the tweet's annotations\n",
    "6. Remove all redundant fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Anonymise annotators\n",
    "\n",
    "Substitute `_session_id` names with anonymised representations, in the form of unique letters.\n",
    "\n",
    "This step cereates the `annotator` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 556 µs\n"
     ]
    }
   ],
   "source": [
    "# 4 different annotators\n",
    "ANNOTATOR_MAP = {\n",
    "    'tweet_annotations-hanne': 'H',\n",
    "    'tweet_annotations-aiko': 'A',\n",
    "    'tweet_annotations-ilya': 'I',\n",
    "    'tweet_annotations-ruben': 'R',\n",
    "    'tweet_annotations-ilya?': 'S',\n",
    "    'tweet_annotations-shoera?': 'S',\n",
    "    'tweet_annotations-shoera': 'O',\n",
    "}\n",
    "\n",
    "def update_annotator(sample):\n",
    "    \"\"\"Assign anonymised annotator labels to each tweet.\"\"\"\n",
    "    sample['annotator'] = ANNOTATOR_MAP[a['_session_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating annotator names: 100%|██████████| 51576/51576 [00:00<00:00, 356315.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 178 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(annotations, desc=\"Updating annotator names\"):\n",
    "    update_annotator(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator overview:\n",
      " - H: 19663\n",
      " - A: 10973\n",
      " - O: 6534\n",
      " - I: 6519\n",
      " - S: 5726\n",
      " - R: 2161\n",
      "time: 30.3 ms\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for a in annotations:\n",
    "    counter[a['annotator']] += 1\n",
    "\n",
    "print(\"Annotator overview:\")\n",
    "for annotator, count in sorted(counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\" - {annotator}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Update annotators\n",
    "\n",
    "Update the `annotators` field with the new annotators names and correct missing annotators (since added incrementally).\n",
    "\n",
    "This step creates the `annotators` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating annotators memory: 100%|██████████| 51576/51576 [00:00<00:00, 86112.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 601 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialise empty annotators memory\n",
    "annotators_memory = {}\n",
    "\n",
    "def update_annotators_memory(sample):\n",
    "    \"\"\"Update the annotators memory with the annotator of the given tweet.\"\"\"\n",
    "    s_id = sample['id']\n",
    "    if s_id not in annotators_memory:\n",
    "        annotators_memory[s_id] = set()\n",
    "    annotators_memory[s_id].add(sample['annotator'])\n",
    "    \n",
    "# Initialise the annotator memory\n",
    "for a in tqdm(annotations, desc=\"Creating annotators memory\"):\n",
    "    update_annotators_memory(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#annotators: #tweets\n",
      "     1     :  46098 \n",
      "     2     :   740  \n",
      "     3     :   709  \n",
      "     4     :   106  \n",
      "     5     :   66   \n",
      "time: 21.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Give overview of number of annotators\n",
    "counter = Counter()\n",
    "for v in annotators_memory.values():\n",
    "    counter[len(v)] += 1\n",
    "\n",
    "print(\"#annotators: #tweets\")\n",
    "for n_anntoators, n_tweets in sorted(counter.items()):\n",
    "    print(f\"{n_anntoators:^11}: {n_tweets:^7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 460 µs\n"
     ]
    }
   ],
   "source": [
    "def assign_anntotors(sample):\n",
    "    \"\"\"Assign the correct annotators to the sample.\"\"\"\n",
    "    sample['annotators'] = sorted(annotators_memory[sample['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning annotators: 100%|██████████| 51576/51576 [00:00<00:00, 470163.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 112 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(annotations, desc=\"Assigning annotators\"):\n",
    "    assign_anntotors(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Readable labels\n",
    "\n",
    "Make the assigned labels easy readable. \n",
    "\n",
    "This step creates the `accept` and `label` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 579 µs\n"
     ]
    }
   ],
   "source": [
    "def update_label(sample):\n",
    "    \"\"\"Assign the correct / readable sentiment label to the sample.\"\"\"\n",
    "    if a['answer'] != 'accept' or not sample['sentiment']:\n",
    "        sample['accept'] = False\n",
    "        sample['label'] = 'REJECT'\n",
    "        return\n",
    "    else:\n",
    "        sample['accept'] = True\n",
    "        sample['label'] = sample['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating labels: 100%|██████████| 51576/51576 [00:00<00:00, 931445.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(annotations, desc=\"Updating labels\"):\n",
    "    update_label(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label overview:\n",
      " - NEUTRAL: 19083\n",
      " - NEGATIVE: 15483\n",
      " - POSITIVE: 15210\n",
      " - REJECT: 1800\n",
      "time: 33.1 ms\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for a in annotations:\n",
    "    counter[a['label']] += 1\n",
    "\n",
    "print(\"Label overview:\")\n",
    "for label, count in sorted(counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\" - {label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept overview:\n",
      " - True: 49776\n",
      " - False: 1800\n",
      "time: 51.3 ms\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for a in annotations:\n",
    "    counter[a['accept']] += 1\n",
    "\n",
    "print(\"Accept overview:\")\n",
    "for accept, count in sorted(counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\" - {accept}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Flag tweets\n",
    "\n",
    "Assign `flag` label to tweets which were flagged by at least one user.\n",
    "\n",
    "This step creates the `flag` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 1028 unique flagged tweets\n",
      "time: 20.9 ms\n"
     ]
    }
   ],
   "source": [
    "# Collect all the flagged tweet IDs\n",
    "flagged_ids = set()\n",
    "\n",
    "# Collect all the flagged IDs\n",
    "for a in annotations:\n",
    "    if 'flagged' in a.keys() and a['flagged']:\n",
    "        flagged_ids.add(a['id'])\n",
    "\n",
    "print(f\"Total of {len(flagged_ids)} unique flagged tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 478 µs\n"
     ]
    }
   ],
   "source": [
    "def check_flag(sample):\n",
    "    \"\"\"Assign flag label to the tweet if necessary.\"\"\"\n",
    "    sample['flag'] = sample['id'] in flagged_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning flagging flag: 100%|██████████| 51576/51576 [00:00<00:00, 1016275.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(annotations, desc=\"Assigning flagging flag\"):\n",
    "    check_flag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged overview:\n",
      " - False: 49232\n",
      " - True: 2344\n",
      "time: 30.7 ms\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for a in annotations:\n",
    "    counter[a['flag']] += 1\n",
    "\n",
    "print(\"Flagged overview:\")\n",
    "for flag, count in sorted(counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\" - {flag}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Correct disagreement\n",
    "\n",
    "Reject the tweets that are annotated by multiple annotators but don't have matching labels.\n",
    "\n",
    "This step creates the `agreement` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 583 µs\n"
     ]
    }
   ],
   "source": [
    "def flag_disagreement(sample):\n",
    "    \"\"\"Reject tweets that are annotated differently by multiple annotators.\"\"\"\n",
    "    # Disagreement only possible if multiple annotators\n",
    "    if len(sample['annotators']) == 1: \n",
    "        sample['agreement'] = True\n",
    "        return\n",
    "    \n",
    "    # Check if annotated differently\n",
    "    labels = {a['label'] for a in annotations if a['id'] == sample['id']}\n",
    "    sample['agreement'] = len(labels) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flagging disagreements: 100%|██████████| 51576/51576 [01:10<00:00, 727.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(annotations, desc=\"Flagging disagreements\"):\n",
    "    flag_disagreement(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement overview:\n",
      " - True: 48801\n",
      " - False: 2775\n",
      "time: 30.2 ms\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for a in annotations:\n",
    "    counter[a['agreement']] += 1\n",
    "\n",
    "print(\"Agreement overview:\")\n",
    "for agreement, count in sorted(counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\" - {agreement}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Remove redundant\n",
    "\n",
    "Remove all the redundant fields from the tweets.\n",
    "\n",
    "**Note:** After this step, the previous steps cannot be executed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 464 µs\n"
     ]
    }
   ],
   "source": [
    "REDUNDANT = {\n",
    "    'validation',  # Covered by 'annotators'\n",
    "    'flagged',  # Covered by 'flag'\n",
    "    '__label',  # Covered by 'label'\n",
    "    'sentiment',  # Covered by 'label'\n",
    "    '_session_id',  # Covered by 'annotator'\n",
    "    'answer',  # Covered by 'accept'\n",
    "    'features',  # Changes later in the pipeline\n",
    "    'prediction',  # Changes later in the pipeline\n",
    "    '_input_hash',  # Irrelevant for future use\n",
    "    '_task_hash',  # Irrelevant for future use\n",
    "    'meta',  # Irrelevant for future use\n",
    "}\n",
    "\n",
    "def remove_redundant_fields(sample):\n",
    "    \"\"\"Remove all the redundant fields from the tweet.\"\"\"\n",
    "    for redundant in REDUNDANT:\n",
    "        if redundant in sample.keys():\n",
    "            del sample[redundant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing redundant fields: 100%|██████████| 51576/51576 [00:00<00:00, 61225.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 844 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for a in tqdm(annotations, desc=\"Removing redundant fields\"):\n",
    "    remove_redundant_fields(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final tweet\n",
    "\n",
    "Show an example of the final annotated tweet-form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 772094208530321400,\n",
       " 'created_at': '2016-09-03 15:29:38',\n",
       " 'text': 'Los gaan pfff 2013 memories',\n",
       " 'text_raw': 'Los gaan pfff 2013 memories',\n",
       " 'truncated': False,\n",
       " 'is_quote': False,\n",
       " 'quoted_lang': '',\n",
       " 'quoted_tweet': '',\n",
       " 'quoted_tweet_raw': '',\n",
       " 'quote_count': 0,\n",
       " 'is_reply': False,\n",
       " 'replied_tweet_id': None,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'hashtags': [],\n",
       " 'user_followers': 1101,\n",
       " 'user_friends': 835,\n",
       " 'user_verified': False,\n",
       " 'user_tweet_count': 34401,\n",
       " 'user_created_at': '2015-03-18 13:09:06',\n",
       " 'annotators': ['H'],\n",
       " 'annotator': 'H',\n",
       " 'accept': True,\n",
       " 'label': 'POSITIVE',\n",
       " 'flag': True,\n",
       " 'agreement': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store\n",
    "\n",
    "Store the results. Overwrite the original `annotations.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 612 ms\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.expanduser('~/data/twitter/tweets_annotated.jsonl'), 'w') as f:\n",
    "    f.write('\\n'.join([json.dumps(a) for a in annotations])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
